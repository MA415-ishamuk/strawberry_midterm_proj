---
title: "MA415 Midterm Project - Isha Mukundan"
format: html
editor: visual
---

## USDA NASS Strawberry Data Set

This document contains the process and results for data cleaning and exploratory data analysis (EDA) OF A USDA NASS Data Set regarding the production and sales of strawberries between the years of 2020 to 2023 in the states of California and Florida.

```{r}
#| label: load libraries
#| echo: false
#| warning: false
#| message: false

library(knitr)  
library(kableExtra)
library(tidyverse)
library(stringr)
library(gridExtra)
```

### Read in Data

The raw USDA NASS Strawberry Data Set that is read in within the code is provided in the associated Github repository under the file name strawb_mar6.csv. An additional file under the name my_functions.R is also provided in the repository which provides function definitions for functions used within the rest of the code- particularly drop_one_value_col().

```{r}
#| label: read in data set + functions
#| echo: false

strawberry <- read_csv("strawb_mar6.csv", 
                       col_names = TRUE,
                       show_col_types = FALSE)

source("my_functions.R")
```

### Clean Data

To provide an initial cleaning of the Strawberry Data Set the function drop_one_value_col() is utilized to remove any redundant columns or columns that are entirely NA- which in both cases are columns that only have one value.

```{r}
#| label: initial clean of strawberry data to gid rid of one value cols
#| echo: false

strawberry_clean <- strawberry |> drop_one_value_col()
```

When looking at the cleaned Strawberry Data Set it can be seen that the data set can be further split into two more broad programs of `CENSUS` and `SURVEY` as the information (variables of interest) held within both programs vastly differ. For example, the `CENSUS` data holds information regarding Gains, Losses, and Net Income while the `SURVEY` data provides insight into utilized chemicals. To therefore ease the process of further data cleaning the cleaned Strawberry Data Set will be split into two new data sets: one consisting of `CENSUS` data and one consisting of `SURVEY` data.

```{r}
#| label: split strawberry_clean into census and survey
#| echo: false

# filter the cleaned Strawberry Data Set to only include entries where the program of interest is Census
straw_cen <- strawberry_clean |> filter(Program == "CENSUS")

# filter the cleaned Strawberry Data Set to only include entries where the program of interest is Survey
straw_sur <- strawberry_clean |> filter(Program == "SURVEY")

# check if either of the newly separated tables have any columns with only one value and remove those
# prt_val = T to show which columns had only one value and were dropped
s_cen <- straw_cen |> drop_one_value_col(prt_val = T)

s_sur <- straw_sur |> drop_one_value_col(prt_val = T)
```

#### Clean Survey Data

As eventually I wanted to gain insight into the usage of chemicals in the production of strawberries, I further cleaned the `SURVEY` Data as the information within this `Program` provided the data regarding the type and usage of chemicals in the growing process. The original `SURVEY` Data consists of columns that have multiple data entries in each as well as columns that hold data that should be placed in a different column.

The `grepl()` function is utilized within the code to recognize patterns within columns of data to shift the location of incorrectly placed data to the correct ones. To tackle the issue regarding multiple data entries in a single cell the `separate_wider_delim()` function is used to split the multiple entries into separate columns based on a chosen delimiter.

First, the non chemical columns in the `SURVEY` data will be cleaned.

```{r}
#| label: clean strawberry survey table (non chemical cols)
#| echo: false

# filter the survey data to only consider the states of California and Florida
s_sur_ca_fl <- s_sur |> filter(State == "CALIFORNIA" | State == "FLORIDA")

# data entries starting with "STRAWBERRIES - " should eventually be split between Category and Item so it will first be  # moved from the Fruit column so only Strawberry remains in the Fruit column
s_sur_ca_fl$`State ANSI`[grepl("STRAWBERRIES -", s_sur_ca_fl$Fruit)] <- s_sur_ca_fl$Fruit[grepl("STRAWBERRIES -", s_sur_ca_fl$Fruit)]
s_sur_ca_fl$Fruit[grepl("STRAWBERRIES -", s_sur_ca_fl$Fruit)] <- "STRAWBERRIES"

# AVG is currently split between Item and Metric but it should eventually all be in its own column of Meas Type so it    # will be temporarily moved until the Meas Type column is produced 
s_sur_ca_fl$Period[grepl("AVG", s_sur_ca_fl$Item)] <- s_sur_ca_fl$Item[grepl("AVG", s_sur_ca_fl$Item)]
s_sur_ca_fl$Period[grepl("AVG", s_sur_ca_fl$Metric)] <- s_sur_ca_fl$Metric[grepl("AVG", s_sur_ca_fl$Metric)]

# split up the Fruit column to just have Strawberry by splitting any entries that have "STRAWBERRIES -" in them
s_sur_ca_fl <- s_sur_ca_fl |> separate_wider_delim(cols = Category,
                                                   delim = '-',
                                                   names = c("Category",
                                                             "item",
                                                             "Meas Type"),
                                                   too_many = "error",
                                                   too_few = "align_start")

# move the temporarily shifted AVG column to Meas Type column
s_sur_ca_fl$`Meas Type`[grepl("AVG", s_sur_ca_fl$Period)] <- s_sur_ca_fl$Period[grepl("AVG", s_sur_ca_fl$Period)]

# move all entries starting with "MEASURED" to the Metric column (these are originally split between Category and Item)
s_sur_ca_fl$Metric[grepl("MEASURED", s_sur_ca_fl$Category)] <- s_sur_ca_fl$Category[grepl("MEASURED", s_sur_ca_fl$Category)]
s_sur_ca_fl$Metric[grepl("MEASURED", s_sur_ca_fl$Item)] <- s_sur_ca_fl$Item[grepl("MEASURED", s_sur_ca_fl$Item)]

# move the columns that originally had STRAWBERRIES in the Fruit column to the Category Column
s_sur_ca_fl$Category[grepl("STRAWBERRIES", s_sur_ca_fl$`State ANSI`)] <- s_sur_ca_fl$`State ANSI`[grepl("STRAWBERRIES", s_sur_ca_fl$`State ANSI`)]

# remove columns that are not of interest for further data analysis
s_sur_ca_fl <- s_sur_ca_fl |> select(-Period, -`Week Ending`, -`State ANSI`, -Item)

# split up the values with "STRAWBERRIES -" that was move back to the Category column into Category and Item with the    # delimiter '-'
s_sur_ca_fl <- s_sur_ca_fl |> separate_wider_delim(cols = Category,
                                                   delim = '-',
                                                   names = c("Category",
                                                             "Item"),
                                                   too_many = "error",
                                                   too_few = "align_start")

# move all of the values placed in the item column from the first separate_wider_delim to the Item column
s_sur_ca_fl$Item[!is.na(s_sur_ca_fl$item)] <- s_sur_ca_fl$item[!is.na(s_sur_ca_fl$item)]

# remove the item column as all necessary information is now in Item
s_sur_ca_fl <- s_sur_ca_fl |> select(-item)

# clean up columns by removing leading spaces using gsub()
s_sur_ca_fl$Category <- gsub("^\\s+", "", s_sur_ca_fl$Category)
```

Next, the chemical related columns of the `SURVEY` data is cleaned in a similar manner- using separate_wider_delim() to separate columns with multiple values and select() and gsub() to respectively remove unwanted columns and remove unwanted parentheses.

```{r}
#| label: clean strawberry survey data (chemical cols)
#| echo: false

# split the Domain column into Domain (CHEMICAL, TOTAL, OTHER, etc) and Type (FUNGICIDE, INSECTISIDE, etc)
s_sur_ca_fl <- s_sur_ca_fl |> separate_wider_delim(cols = Domain,
                                                   delim = ',',
                                                   names = c("Domain",
                                                             "Type"),
                                                   too_many = "error",
                                                   too_few = "align_start")

# split Domain Category into rep and Name- rep will be removed as it is info already provided in the Domain and Type     # columns
s_sur_ca_fl <- s_sur_ca_fl |> separate_wider_delim(cols = `Domain Category`,
                                                   delim = ':',
                                                   names = c("rep",
                                                             "Name"),
                                                   too_many = "error",
                                                   too_few = "align_start")
# remove rep column
s_sur_ca_fl <- s_sur_ca_fl |> select(-rep)

# split newly made Name into Name and Code with the delimiter of "="
s_sur_ca_fl <- s_sur_ca_fl |> separate_wider_delim(cols = Name,
                                                   delim = '=',
                                                   names = c("Name",
                                                             "Code"),
                                                   too_many = "error",
                                                   too_few = "align_start")

# clean up columns by removing parentheses ()
s_sur_ca_fl$Name <- gsub("^\\s?\\(", "", s_sur_ca_fl$Name)
s_sur_ca_fl$Name <- gsub("\\)$", "", s_sur_ca_fl$Name)

s_sur_ca_fl$Code <- gsub("^\\s+", "", s_sur_ca_fl$Code)
s_sur_ca_fl$Code <- gsub("\\)$", "", s_sur_ca_fl$Code)

```

The cleaned Strawberry `SURVEY` data is saved as a .csv for further analysis purposes. This file is found within the Github repository under the name survey_clean.csv

```{r}
#| label: save cleaned survey data as .csv
#| echo: false

write.csv(s_sur_ca_fl, file = "survey_clean.csv", row.names = T)
```

Since further analysis will consider and compare the state of California and Florida I split the cleaned `SURVEY` data into two further data sets: one where the state of interest is California and one where it is Florida.

```{r}
#| label: split cleaned survey data into california and florida
#| echo: false

# filter the survey data to only consider the state of California 
s_sur_ca <- s_sur_ca_fl |> filter(State == "CALIFORNIA")

# filter the survey data to only consider the state of Florida 
s_sur_fl <- s_sur_ca_fl |> filter(State == "FLORIDA")
```

#### Clean Census Data

As I wanted to also gain insight into the connection between of sales, production, and net income for strawberries production within the two states, I further cleaned the `CENSUS` Data as the information within this `Program` provided the economic data needed to gain clarity on these topics. Like the `SURVEY` data, the original `CENSUS` Data also consists of columns that have multiple data entries as well as columns that hold data that should be placed in a different column.

```{r}
#| label: clean strawberry census data
#| echo: false

# filter the census data to only consider the states of California and Florida
s_cen_ca_fl <- s_cen |> filter(State == "CALIFORNIA" | State == "FLORIDA")

# remove columns that are necessary for further data analysis
s_cen_ca_fl <- s_cen_ca_fl |> select(-`State ANSI`)

# look what unique values are found within the Commodity column
unique(s_cen_ca_fl$Commodity)

# Commodity column has two values, INCOME and STRAWBERRIES, which hold differing information within the other columns so # the census data will be separated into two further data sets: one where the Commodity of interest is INCOME and one    # where it is STRAWBERRIES
s_cen_ca_fl_inc <- s_cen_ca_fl |> filter(Commodity == "INCOME, NET CASH FARM")
s_cen_ca_fl_str <- s_cen_ca_fl |> filter(Commodity == "STRAWBERRIES")

# check if either of the newly separated tables have any columns with only one value and remove those
s_cen_ca_fl_inc <- s_cen_ca_fl_inc |> drop_one_value_col(prt_val = T)
s_cen_ca_fl_str <- s_cen_ca_fl_str |> drop_one_value_col(prt_val = T)
```

Now looking just at the data set where the `Commodity` of interest is `INCOME`, the same process undertaken to clean the `SURVEY` data is repeated here for the `CENSUS` data through the use of the functions separate_wider_delim(), select(), and gsub(). Here separate_wider_delim() is used to separate and get rid of the leading "OF OPERATIONS - " and "OF PRODUCERS - " with "F" and then "-" as delimiters.

```{r}
#| label: clean strawberry census data (commodity = income)
#| echo: false

# separate "OF OPERATIONS -" and "OF PRODUCERS -" between the F in OF to remove the leading OF
s_cen_ca_fl_inc <- s_cen_ca_fl_inc |> separate_wider_delim(cols = Item,
                                                   delim = 'F ',
                                                   names = c("remove",
                                                             "Type"),
                                                   too_many = "error",
                                                   too_few = "align_start")

# separate "OPERATIONS -" and "PRODUCERS -" using "- " as a delimiter to seperate the information within Type and Inc    # (Income) Type
s_cen_ca_fl_inc <- s_cen_ca_fl_inc |> separate_wider_delim(cols = Type,
                                                   delim = '- ',
                                                   names = c("Type",
                                                             "Inc Type"),
                                                   too_many = "error",
                                                   too_few = "align_start")

# split Domain Category into rep and Range- rep will be removed as it is info already provided in the Domain
s_cen_ca_fl_inc <- s_cen_ca_fl_inc |> separate_wider_delim(cols = `Domain Category`,
                                                   delim = ': ',
                                                   names = c("rep",
                                                             "Range"),
                                                   too_many = "error",
                                                   too_few = "align_start")

# remove remove and rep columns
s_cen_ca_fl_inc <- s_cen_ca_fl_inc |> select(-remove, -rep)

# clean up columns by removing parentheses ()
s_cen_ca_fl_inc$Range <- gsub("^\\s?\\(", "", s_cen_ca_fl_inc$Range)
s_cen_ca_fl_inc$Range <- gsub("\\)$", "", s_cen_ca_fl_inc$Range)
```

The values in `FARM SALES` are provided as ranges between two values and to make data visualization easier I split the Range column into its `Lower` and `Upper` bounds. These ranges however had additional information indicating the units of interest (\$ or ACRES) and so gsub() was used so that only numerical values were left. There were additionally two special cases where OR MORE and LESS THAN were used, so to ensure only numerical values were left I changed LESS THAN (Value) to go from 0 to the particular value by using gsub() to substitute out LESS THAN for "0-" and used separate_wider_delim to keep 0 in the `Lower` column and (Value) in the Upper bound column. A similar process was utilized for OR MORE but rather than 0 the `Upper` bound for that row was left as NA, as the cap for the Farm Sales value is unknown.

```{r}
#| label: clean strawberry census data (commodity = income) - split range into numerical values
#| echo: false

# separate the Range column into two new columns representing the Lower and Upper bounds
s_cen_ca_fl_inc <- s_cen_ca_fl_inc |> separate_wider_delim(cols = Range,
                                                   delim = ' TO ',
                                                   names = c("Lower",
                                                             "Upper"),
                                                   too_many = "error",
                                                   too_few = "align_start")

# use gsub() to get rid of the trailing units (ACRES OR $)
s_cen_ca_fl_inc$Upper <- gsub("ACRES", "", s_cen_ca_fl_inc$Upper)
s_cen_ca_fl_inc$Upper <- gsub("\\$", "", s_cen_ca_fl_inc$Upper)

# use gsub() to get rid of the "LESS THAN" or "OR MORE" to allow the Lower and Upper columns to be only numerical values
s_cen_ca_fl_inc$Lower <- gsub(" OR MORE \\$", "", s_cen_ca_fl_inc$Lower)
s_cen_ca_fl_inc$Lower <- gsub(" OR MORE ACRES", "", s_cen_ca_fl_inc$Lower)

s_cen_ca_fl_inc$Lower <- gsub("LESS THAN ", "0 -", s_cen_ca_fl_inc$Lower)
s_cen_ca_fl_inc$Lower <- gsub("1,000 \\$", "999", s_cen_ca_fl_inc$Lower)

# seperate the Lower column that now has "0-" as the artificial lower bound for the "LESS THAN" row into Lower, which    # will include the 0, and up which is a temporary column that will be removed
s_cen_ca_fl_inc <- s_cen_ca_fl_inc |> separate_wider_delim(cols = Lower,
                                                   delim = ' -',
                                                   names = c("Lower",
                                                             "up"),
                                                   too_many = "error",
                                                   too_few = "align_start")

# move the values from the temporary column up to the actual column UPPER and remove up
s_cen_ca_fl_inc$Upper[grepl("999", s_cen_ca_fl_inc$up)] <- s_cen_ca_fl_inc$up[grepl("999", s_cen_ca_fl_inc$up)]
s_cen_ca_fl_inc <- s_cen_ca_fl_inc |> select(-up)
```

The cleaned Strawberry `CENSUS` data where `Commodity` is `INCOME` is saved as a .csv for further analysis purposes. This file is found within the Github repository under the name census_inc_clean.csv

```{r}
#| label: save cleaned census data (commodity = income) as .csv
#| echo: false

write.csv(s_cen_ca_fl_inc, file = "census_inc_clean.csv", row.names = T)
```

Since further analysis will consider and compare the state of California and Florida I split the cleaned `CENSUS` data, where the `Commodity` is `INCOME` into two further data sets: one where the state of interest is California and one where it is Florida. Within each data set however, there is additionally a separation between `OPERATIONS` and `PRODUCERS` so each State specific data set will be further split into two new data sets so that there is an individual `OPERATIONS` and `PRODUCERS` for both states.

```{r}
#| label: split cleaned census data (commodity = income) by both state and type
#| echo: false

# filter the census data to only consider the state of California 
s_cen_ca <- s_cen_ca_fl_inc |> filter(State == "CALIFORNIA")

# filter the survey data to only consider the state of Florida 
s_cen_fl <- s_cen_ca_fl_inc |> filter(State == "FLORIDA")

# filter the state specifies census data by "OPERATIONS" AND "PRODUCERS"
s_cen_ca_op <- s_cen_ca |> filter(Type == "OPERATIONS ")
s_cen_ca_pr <- s_cen_ca |> filter(Type == "PRODUCERS ")

s_cen_fl_op <- s_cen_fl |> filter(Type == "OPERATIONS ")
s_cen_fl_pr <- s_cen_fl |> filter(Type == "PRODUCERS ")
```

Now looking at the data set where the `Commodity` of interest is `STRAWBERRIES`, the same process undertaken to clean the earlier `CENSUS` data is repeated here the use of the functions grepl() and select(). Here grepl() is used to move all the entries in the `Item` column that begin with "MEASURED" to the `Metric` column and all entries with "ORGANIC -" to the `Item` column from '`Category`. This second shift leaves everything in Category to have only one value so it can be dropped from the cleaned final data.

```{r}
#| label: clean strawberry census data (commodity = strawberry)
#| echo: false

# move all entries with "MEASURED" from the Item column to the Metric column
s_cen_ca_fl_str$Metric[grepl("MEASURED", s_cen_ca_fl_str$Item)] <- s_cen_ca_fl_str$Item[grepl("MEASURED", s_cen_ca_fl_str$Item)]

# move all entries with "ORGANIC -" from the Category column to the Item column
s_cen_ca_fl_str$Item[grepl("ORGANIC -", s_cen_ca_fl_str$Category)] <- s_cen_ca_fl_str$Category[grepl("ORGANIC -", s_cen_ca_fl_str$Category)]

# the Category column now only has one value so it can be removed from the cleaned data
s_cen_ca_fl_str <- s_cen_ca_fl_str |> select(-Category)
```

The cleaned Strawberry `CENSUS` data where `Commodity` is `STRAWBERRIES` is saved as a .csv for further analysis purposes. This file is found within the Github repository under the name census_str_clean.csv

```{r}
#| label: save cleaned census data (commodity = strawberries) as .csv
#| echo: false

write.csv(s_cen_ca_fl_str, file = "census_str_clean.csv", row.names = T)
```

Since further analysis will consider and compare the state of California and Florida I split the cleaned `CENSUS` data, where the `Commodity` is `STRAWBERRIES` into two further data sets: one where the state of interest is California and one where it is Florida.

```{r}
#| label: split cleaned census data (commodity = strawberry) by state
#| echo: false

# filter the census data to only consider the state of California 
s_cen_ca_str <- s_cen_ca_fl_str |> filter(State == "CALIFORNIA")

# filter the census data to only consider the state of Florida 
s_cen_fl_str <- s_cen_ca_fl_str |> filter(State == "FLORIDA")
```

### Data Analysis

Following the completion of the Data Cleaning portion of the project, I now focus on performing exploratory data analysis to uncover patterns and gain insights into potential trends and explanations that underlie the current production, growth, and sales system of strawberries. By looking into the use of chemicals in the growth of strawberries, insights can be gained regarding the impact of various chemicals on yield, quality, and overall productivity. This can help identify which chemicals are most effective and sustainable in strawberry cultivation, as well as how environmental or regulatory factors might be influencing their usage.

Furthermore, examining how farm sales affect net income provides valuable context for understanding the financial health of strawberry producers. By identifying the farm sales ranges where producers begin to experience positive net income, we can uncover the thresholds at which farm operations become profitable. This information is vital for growers and stakeholders in planning and optimizing production and sales strategies.

Additionally, understanding how much sales are made based on market type—whether organic, fresh, or processing— can reveal significant insights into market preferences, demand, and pricing dynamics. This information can help to guide producers to tailor their marketing and operational efforts more effectively. Analyzing this data can help to identify which market types are more lucrative and explore the potential for growth in emerging markets such as organic strawberries.

#### Data Analysis - Chemicals

An important area of focus in this analysis is the use of chemicals in strawberry cultivation. Chemicals such as pesticides, herbicides, and fungicides are commonly used to enhance yields and protect crops from pests and diseases. However, concerns about the environmental impact and potential health risks associated with these chemicals have sparked ongoing debates. By examining the trends in chemical usage, particularly in major strawberry-producing states like California and Florida, this section aims to understand the patterns and implications of chemical applications in strawberry farming. This insight is crucial for identifying sustainable practices that balance productivity with environmental and consumer health considerations.

This data set provides insights into the four main classes of chemicals used (fungicides, herbicide, insecticide, other) as well as fertilizers and so I was interested in the particular breakdown of which class of chemicals was most used in each state and whether the main class of chemical used between the two differed. To visualize this comparison I created a 2 variable bar graph, using ggplot, to show the difference in counts of chemical and fertilizer uses for the four major classes of chemicals between California and Florida.

```{r}
#| label: create plot to investigate chemical class use 
#| echo: false

# calculate a count of each type of chemical class and fertilizer from the California survey data
ca_chem_sum <- s_sur_ca %>%
  group_by(Domain, Type) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

# to more easily make the 2 variable plot later add a column to ca_chem_sum to show the associated state is California
ca_chem_sum$State <- c("CALIFORNIA")


# calculate a count of each type of chemical class and fertilizer from the Florida survey data
fl_chem_sum <- s_sur_fl %>%
  group_by(Domain, Type) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

# to more easily make the 2 variable plot later add a column to ca_chem_sum to show the associated state is Florida
fl_chem_sum$State <- c("FLORIDA")

# bind together the two data sets (by row) to be used as the base data frame for ggplot2 to plot from
ca_fl_chem_sum <- rbind(ca_chem_sum, fl_chem_sum) 
ca_fl_chem_sum <- ca_fl_chem_sum %>%
  mutate(Type = ifelse(is.na(Type), "FERTILIZER", Type))

# create a 2 variable bar graph using ggplot to show the distribution of chemical class between the two states
ggplot(ca_fl_chem_sum, aes(fill=State, y=count, x=Type)) +
  geom_bar(position='dodge', stat='identity') +
  geom_text(aes(label = count), position = position_dodge(width = 0.9), vjust = -0.5) +
  ggtitle('Chemical Type Distribution in California and Florida (2020-2023)') +
  xlab('Chemical Type') +
  ylab('Count') +
  scale_fill_manual('State', values=c('seagreen4','slategray2'))
```
Looking at the produced bar graph, it can be seen how California seems to have a higher reliance on chemicals compared to Florida, as for all chemical types other than herbicides California has a higher count. While fungicides are the most commonly used chemical in Florida, California's most commonly used chemical type is insecticides but it too often uses fungicides- even more than Florida. This discrepancy in the usage amount and type of chemical class used can be due to the fact that California may face greater pest and disease pressures, whereas Florida may focus on different environmental or farming practices that are less reliant on chemicals even when faced with such pressures. These differences in chemical usage could have important implications for sustainability and environmental impact, highlighting the need for tailored strategies in each state to optimize agricultural practices and manage pests and diseases effectively.

Now that more broad insight into the differences between the classes of chemicals between the two states have been found, I am interested in seeing if there are any specific chemicals that are commonly used in both California and Florida and how their usage amounts differ between each other as well as over the years. To help satisfy this curiosity I created a table to visualize the top 10 chemicals used in each state respectively based in the amount used measured in pounds. By filtering each data set based on the values measured in pounds and summing up this measurement for each chemical name, a running total of the total usage of a particular chemical could be found.

```{r}
#| label: create a table to visualize the top 10 chemcials used in both states 
#| echo: false

# first make the value column numerical from character by getting rid of the comma and using as.numeric()
s_sur_ca$Value <- as.numeric(gsub(",", "", s_sur_ca$Value))
s_sur_fl$Value <- as.numeric(gsub(",", "", s_sur_fl$Value))

# calculate the total usage in pounds for each chemical in California
tot_use_lb_ca <- s_sur_ca %>%
  filter(Metric == " MEASURED IN LB" & Domain != "TOTAL)" & Domain != "FERTILIZER") %>%
  group_by(Name) %>%
  summarise(`Total Usage (LB)` = sum(Value, na.rm = TRUE)) %>%
  arrange(desc(`Total Usage (LB)`))

# calculate the total usage in pounds for each chemical in Florida
tot_use_lb_fl <- s_sur_fl %>%
  filter(Metric == " MEASURED IN LB" & Domain != "TOTAL)" & Domain != "FERTILIZER") %>%
  group_by(Name) %>%
  summarise(`Total Usage (LB)` = sum(Value, na.rm = TRUE)) %>%
  arrange(desc(`Total Usage (LB)`))

# extract the top 10 chemicals for each state by total usage (started from 2 as first row was TOTAL)
top_chem_ca <- tot_use_lb_ca |> slice(2:11)
top_chem_fl <- tot_use_lb_fl |> slice(2:11)

# to make a 2 variable table easier to generate add a column to each data set to explain which state it came from
top_chem_ca$State <- "California"
top_chem_fl$State <- "Florida"

# combine both tables into one using column bind
colnames(top_chem_fl) <- paste(colnames(top_chem_fl), "_fl", sep = "")
top_chem <- cbind(top_chem_ca, top_chem_fl)

# select the columns of interest for the final table - use the added _fl to differentiate variables of the same name     # between the two states
top_chem_table <- top_chem |> select(Name, `Total Usage (LB)`, Name_fl, `Total Usage (LB)_fl`)
colnames(top_chem_table) <- gsub("_fl", "", colnames(top_chem_table))

# display the combined table showcasing the top 10 chemicals per state using kable
top_chem_table |>
  kbl(caption = "Top 10 Most Used Chemicals in California and Florida") |>
  kable_classic(full_width = F, html_font = "Cambria") |> 
  add_header_above(c("California" = 2, "Florida" = 2))
```

Based on the table above it can be seen that the three most used chemicals common to both California and Florida (based on their total usage in pounds) are Captan, Thiram, and Cyprodinil- all of which fall under the fungicide class of chemicals. According to PubMed both Captan and Thiram as chemicals exhibit moderate acute toxicity if encountered via oral or inhalation exposure (Cat II and III), while Cyprodinil poses relatively little toxicity risk (Cat III & I4). The fact that these chemicals which are some of the most commonly used in both states do to some extent post toxicity risk mY lead consumers to be more wary about purchasing such products if they are more aware about it in the future. These three chemicals were the top three most used in Florida which follows what was seen in the bar graph above where of the classes of chemicals Florida had the most number of fungicides. The largest use of the fungicides in Florida may imply that in this state Fungi are the largest threat the strawberry growing compared to insects or herbs. The top two chemicals used in California are under the the other class of chemicals, which I found interesting as with the high number of fungicides and insecticides seen in the bar graph to be used in California I was expecting their to be both classes in the top 5 most used chemicals.

After finding the three chemicals that were most commonly used in both states, I was interested in uncovering by how much that total usage of each of these chemicals changed over the years for California and Florida. To visualize this, I create a line plot, using ggplot, that plotted the total usage trajectory of each of the three top chemicals over the years 2021 and 2023 for the two states.

```{r}
#| label: create a plot to visualize how the top 3 shared chemical usage changed over time in both states 
#| echo: false

# filter the top 10 chemical data sets to just include data regarding the three chemicals of choice
top_3chem_ca <- top_chem_ca |> filter(Name == "CAPTAN " | Name == "THIRAM " | Name =="CYPRODINIL ")
top_3chem_fl <- top_chem_fl |> filter(Name_fl == "CAPTAN " | Name_fl == "THIRAM " | Name_fl =="CYPRODINIL ")

# calculate the yearly trends for the top 3 chosen chemicals for California
yr_chem_ca <- s_sur_ca %>%
  filter(Name %in% top_3chem_ca$Name, Metric == " MEASURED IN LB" & Domain != "TOTAL)" & Domain != "FERTILIZER") %>%
  group_by(Year, Name) %>%
  summarise(yearly_usage = sum(Value, na.rm = TRUE))

# calculate the yearly trends for the top 3 chosen chemicals for Florida
yr_chem_fl <- s_sur_fl %>%
  filter(Name %in% top_3chem_fl$Name_fl, Metric == " MEASURED IN LB" & Domain != "TOTAL)" & Domain != "FERTILIZER") %>%
  group_by(Year, Name) %>%
  summarise(yearly_usage = sum(Value, na.rm = TRUE))


# create line plots of Yearly Usage of the three chemicals from 2021 to 2023 for California and Florida
yr_chem_ca_plot <- ggplot(yr_chem_ca, aes(x = Year, y = yearly_usage*1e-3, color = Name, group = Name)) +
  geom_line() +                            
  geom_point() +                           
  labs(title = "Yearly Usage of Chemicals in California",
       x = "Year",
       y = "Yearly Usage (kip)",
       color = "Chemical Type") +
  scale_color_manual(values = c("red", "blue", "green"))+ 
  scale_x_continuous(breaks = c(2021, 2023))

yr_chem_fl_plot <- ggplot(yr_chem_fl, aes(x = Year, y = yearly_usage*1e-3, color = Name, group = Name)) +
  geom_line() +                            
  geom_point() +                           
  labs(title = "Yearly Usage of Chemicals in Florida",
       x = "Year",
       y = "Yearly Usage (kip)",
       color = "Chemical Type") +
  scale_color_manual(values = c("red", "blue", "green"))+ 
  scale_x_continuous(breaks = c(2021, 2023))

# use grid.arrange() to plot both graphs in the same viewing window
grid.arrange(yr_chem_ca_plot, yr_chem_fl_plot, ncol = 1)
```
From the two line graphs produced above, it can be seen that for both California and Florida the usage of Captan and Cyprodinil have slowly increased over the years while the action of the chemical Thiram changes between the states. In California, the yearly usage of the chemical Thiram also goes up (similar to the other two chemicals), but in Florida the yearly usage of the same chemical drops instead. In California, the upward trend in Thiram usage could be driven by rising pest challenges or changing environmental factors that make this specific chemical more necessary. In contrast, the declining use of Thiram in Florida may suggest a shift in pest management strategies, possibly due to changes in pest pressure or the adoption of alternative chemicals to counter the particular fungi that this chemical in particular addresses. This might be the case rather than a more overarching shift away from fungicides as the other two fungicides (Captan and Cyprodinil) are still being utilized as the years progress.

#### Data Analysis - Income

An additionally important area of focus in this analysis is the economic trends that follow strawberry production within the two states. Understanding how different levels of sales contribute to profitability is crucial for evaluating the financial sustainability of such farms. Identifying the sale thresholds at which farms begin to experience positive net income, can help uncover key insights that can optimize production and sales strategies. Additionally, examining income in relation to market types—whether organic, fresh, or processing—can provide valuable context for understanding market preferences. This helps identify which market types are more lucrative, allowing producers to better target their efforts and capitalize on high-demand areas.

The data provided within the `CENSUS` portion of the data set provides insight into the correlation between Farm Sales and Net Income and I was interested in seeing the relationship between the two variables, particularly in regards to at which range of farm sales does the farm being to produce a positive net income. To visualize this I created a table that shows the net income of each state for a give range of Farm Sales in dollars.

```{r}
#| label: create figures to visualize net income by farm sales
#| echo: false

# filter the California census data to only consider Farm Sales as the domain
netinc_ca_farm <- s_cen_ca_pr |> filter(Domain == "FARM SALES")

# the values in Farm Sales are originally chars so first convert to numeric so that the rows can be reordered based on   # ascending values
netinc_ca_farm$Lower <- as.numeric(gsub(",", "", netinc_ca_farm$Lower))
netinc_ca_farm$Upper <- as.numeric(gsub(",", "", netinc_ca_farm$Upper))
netinc_ca_farm <- netinc_ca_farm[order(netinc_ca_farm$Lower, decreasing = F), ]

# filter the Florida census data to only consider Farm Sales as the domain
netinc_fl_farm <- s_cen_fl_pr |> filter(Domain == "FARM SALES")

# the values in Farm Sales are originally chars so first convert to numeric so that the rows can be reordered based on   # ascending values
netinc_fl_farm$Lower <- as.numeric(gsub(",", "", netinc_fl_farm$Lower))
netinc_fl_farm$Upper <- as.numeric(gsub(",", "", netinc_fl_farm$Upper))
netinc_fl_farm <- netinc_fl_farm[order(netinc_fl_farm$Lower, decreasing = F), ]
colnames(netinc_fl_farm) <- paste(colnames(netinc_fl_farm), "_fl", sep = "")

# combine both tables into one using column bind
netinc_farm <- cbind(netinc_ca_farm, netinc_fl_farm)

# select the columns of interest for the final table
netinc_farm_table <- netinc_farm |> select(Lower, Upper, Value, `CV (%)`, Value_fl, `CV (%)_fl`)

# make the values in the table easier to read by labeling them with dollars and writing them in short had (by millions)
# remove commas in the char so it is able to convert to numeric
netinc_farm_table$Value <- as.numeric(gsub(",", "", netinc_farm_table$Value))
# create a more concise format for money
netinc_farm_table$Value <- scales::label_dollar(scale = 1e-6, suffix = "M")(netinc_farm_table$Value)
# remove commas in the char so it is able to convert to numeric
netinc_farm_table$Value_fl <- as.numeric(gsub(",", "", netinc_farm_table$Value_fl))
# create a more concise format for money
netinc_farm_table$Value_fl <- scales::label_dollar(scale = 1e-6, suffix = "M")(netinc_farm_table$Value_fl)

# rename the columns to get rid of the _fl that was used when selecting columns for the table
colnames(netinc_farm_table) <- gsub("_fl", "", colnames(netinc_farm_table))

# display the combined table showcasing the average net income by farm sales per state using kable
netinc_farm_table |>
  kbl(caption = "California and Florida Average Net Income in 2022 by Farm Sales") |> 
  kable_classic(full_width = F, html_font = "Cambria") |> 
  add_header_above(c("Farm Sales ($)" = 2, "California" = 2, "Florida" = 2))
```

Looking at the table above it can be seen how Florida begins to make a profitable (net positive) income at an earlier Farm Sale range when compared to California. For Florida, a positive net income starts as Farm Sales are between \$50,000 and \$99,999 while California only starts seeing a positive net income when Farm Sales are significantly higher between \$250,000 and \$499,999. This disparity suggests that Florida farmers can reach profitability at smaller scales, likely due to factors such as lower operational costs or reduced land and labor expenses. Its agricultural industry may also face less competition, allowing producers to become profitable more easily. On the other hand, California's higher costs, driven by factors like labor, land, environmental regulations, and a larger, more competitive agricultural industry, demand higher sales to offset these expenses and reach profitability. Additionally, California's farmers may deal with larger production volumes or more complex farming practices that contribute to higher operational costs. This difference in profitability thresholds also highlights the impact of scale economies in California, where larger-scale operations are needed to cover costs and achieve profit.

In addition to looking at the affect of Farm Sales on Net Income I was also interested in looking to see how sales in general were affected based on the market type used- whether it is organic, fresh market, or processing. However, the data in the given data set is very limited and missing some values, so the full scope of my question could not be considered but parts of it are able to. California has information for all three market types (organic, fresh market, and processing) when sales are `MEASURED BY CWT`, so I am interested to compare and see which market type produces the most sales for strawberries grown in California. I visualized this comparison through the generation of a bar graph, using ggplot, the compares the sale methods by weight.   

```{r}
#| label: create figure to compare organic, fresh market, and processing sales in california
#| echo: false

# filter California census data (commodity = strawberry) based on entries that are "MEASURED IN CWT"
s_cen_ca_cwt <- s_cen_ca_str |> filter(Metric == " MEASURED IN CWT")

# remove the " - SALES" from the Item column as it is repetitive for labeling
s_cen_ca_cwt$Item <- gsub(" - SALES", "", s_cen_ca_cwt$Item)

# to ensure the y-axis values are ordered correctly convert the Value column that was originally chars to numeric
s_cen_ca_cwt$Value <- as.numeric(gsub(",", "", s_cen_ca_cwt$Value))*1e-6

# create a bar graph to compare the Sale Methods by Weight for California
ggplot(s_cen_ca_cwt, aes(x = Item, y = Value)) +
  geom_bar(stat = "identity", fill = "seagreen4") +  
  geom_text(aes(label = Value), position = position_dodge(width = 0.9), vjust = -0.5) +
  labs(title = "Sale Methods by Weight for California",
       x = "Sale Type",
       y = "Value (in M CWT)",
       fill = "State")
```
The bar graph highlights that in California, the vast majority of strawberry sales come from the fresh market and organic sectors rather than processing, suggesting a strong consumer preference for fresh and organic produce. The larger pull by the fresh and organic markets to consumers may be to a perception that fresher produce is better quality and more beneficial to those who eat it as well as the environment. This means that it would be import for California farmers to prioritize these markets, as they offer higher profitability (sales) compared to processed strawberries, that could come in the form of jams or jellies, meaning that more land, space, and workforce could be allocated for these sectors. 

In the given data set however, Florida has no processing data and California only has hidden values for the Fresh Market and Processing sales in $, so instead I will compare organic and fresh market sales measured by weight/volume (in CWT) between the two states. To make this comparison I will generate a 2 variable bar graph, using ggplot, that compares the Value of product sold, in weight, for each market type between the two states. 

```{r}
#| label: create figure to compare organic + fresh market sales between california and florida
#| echo: false

# filter the sales data set to only include ORGANIC and FRESH MARKET sales as we have data for those
s_cen_sales <- s_cen_ca_fl_str |> filter(Item == " ORGANIC - SALES" | Item == " FRESH MARKET - SALES")

# filter the data set once more to just take the metric when it is MEASURED IN CWT as it has values for both cases above
s_cen_sales <- s_cen_sales |> filter(Metric == " MEASURED IN CWT")

# remove " - SALES" as it is repetitive for labeling
s_cen_sales$Item <- gsub(" - SALES", "", s_cen_sales$Item)

# to ensure the y-axis values are ordered correctly convert the Value column that was originally chars to numeric
s_cen_sales$Value <- as.numeric(gsub(",", "", s_cen_sales$Value))*1e-6

# create a bar graph to compare the Fresh and Organic Market Sales by Weight for both states
ggplot(s_cen_sales, aes(x = Item, y = Value, fill = State)) +
  geom_bar(stat = "identity", position = "dodge") + 
  geom_text(aes(label = Value), position = position_dodge(width = 0.9), vjust = -0.5) +
  labs(title = "Organic and Fresh Market Sales by Weight for California and Florida",
       x = "Sale Type",
       y = "Value (in M CWT)",
       fill = "State") +
  scale_fill_manual('State', values=c('seagreen4','slategray2'))
```
From the above bar graph it can be seen that for a given state the weight of produce sold is either exactly the same or very similar regardless of whether the sale type was in Fresh Market or Organic. However, comparing the two states together, it can be seen that by volume in both sale types California sells a significant amount more of strawberries, around 21 times more, than Florida. This stark contrast points to California’s larger agricultural scale, more extensive production capacity, and perhaps greater market reach allowing the state to sell much more of its goods. California’s dominance in strawberry sales likely reflects its established infrastructure, larger growing areas, and longer growing seasons, while Florida, though a significant producer (the second largest of all the states) seems to operate on a comparatively smaller scale.

### Conclusion

In conclusion, the data cleaning and exploratory data analysis (EDA) processes have provided valuable insights into the complexities of strawberry production, sales, and chemical usage across California and Florida. These preliminary analyses have allowed for the identification of key patterns, such as the differing profitability thresholds between the two states and the significant difference in the volume of strawberries sold. However, this is just the beginning as the analysis I provided so far in this document has only scratched the surface of all the information and comparisons that could be generated through the original data set- meaning that are many more areas that need further exploration. Further analysis into this data set as well as creating others through USDA that may focus even more heavily on, for example, the economic situation of strawberry production, could help optimize farming strategies and contribute further to more sustainable practices. Continuing analysis through this cleaned data set can help uncover more valuable insights for strawberry producers and stakeholders in the agricultural industry.
